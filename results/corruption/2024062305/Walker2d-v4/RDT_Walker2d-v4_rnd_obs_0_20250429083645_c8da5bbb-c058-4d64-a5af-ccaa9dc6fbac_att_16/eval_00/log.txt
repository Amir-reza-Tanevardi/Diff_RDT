Logging to results/corruption/2024062305/Walker2d-v4/RDT_Walker2d-v4_rnd_obs_0_20250429083645_c8da5bbb-c058-4d64-a5af-ccaa9dc6fbac_att_16/eval_00
eval_every: 1
n_episodes: 100
device: cuda
num_epochs: 100
num_updates_on_epoch: 1000
use_diff_att: False
embedding_dim: 128
num_layers: 3
num_heads: 16
seq_len: 20
episode_len: 1000
attention_dropout: 0.0
residual_dropout: 0.1
embedding_dropout: None
mlp_embedding: False
mlp_head: False
mlp_reward: True
embed_order: rsa
learning_rate: 0.0001
betas: (0.9, 0.999)
weight_decay: 0.0001
clip_grad: 0.25
batch_size: 64
update_steps: 100000
warmup_steps: 10000
reward_scale: 0.001
normalize: True
normalize_reward: False
loss_fn: wmse
wmse_coef: (0.0, 0.0)
reward_coef: 1.0
recalculate_return: False
correct_freq: 1
correct_start: 50
correct_thershold: None
target_returns: (12000.0, 6000.0)
eval_id: 00
eval_only: True
eval_attack: True
eval_attack_eps: 0.01
eval_attack_mode: random
checkpoint_dir: results/corruption/2024062305/Walker2d-v4/RDT_Walker2d-v4_rnd_obs_0_20250429083645_c8da5bbb-c058-4d64-a5af-ccaa9dc6fbac_att_16
use_wandb: 0
group: 2024062305
env: Walker2d-v4
minari_dataset_id: minari/walker2d-medium-v2
seed: 0
down_sample: True
sample_ratio: 0.1
debug: False
alg_type: RDT
logdir: results/corruption
dataset_path: your_dataset_path
save_model: True
corruption_agent: IQL
corruption_seed: 0
corruption_mode: random
corruption_obs: 1.0
corruption_act: 0.0
corruption_rew: 0.0
corruption_rate: 0.3
use_original: 0
same_index: 0
froce_attack: 0
Load new dataset from your_dataset_path/log_attack_data/Walker2d-v4/random_0_ratio_0.1_obs_1.0_0.3.pth
random observations
Attack name: _ratio_0.1_obs_1.0_0.3
Dataset: 104 trajectories
State mean: [[ 1.22334051e+00 -1.67085797e-02 -4.14643609e-01 -6.83707640e-03
   2.56521932e-01 -9.76107965e-02 -5.49006676e-01  1.15862676e-01
   4.96850683e+00 -2.91792073e-03  1.98722032e-03 -4.33489993e-02
  -2.10986769e-02  6.35574327e-01 -1.25708428e-02  7.40375992e-02
   5.35483126e-01]], std: [[0.06329407 0.23992098 0.41358941 0.09799204 0.64112285 0.21625538
  0.4059761  0.67789316 1.40967205 0.67806036 2.35349475 3.93122688
  1.96666773 6.00912943 3.11459959 5.43827092 6.79833387]]
Network: 
DecisionTransformer(
  (emb_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (out_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (timestep_emb): Embedding(1020, 128)
  (state_emb): Linear(in_features=17, out_features=128, bias=True)
  (action_emb): Linear(in_features=6, out_features=128, bias=True)
  (return_emb): Linear(in_features=1, out_features=128, bias=True)
  (blocks): ModuleList(
    (0-2): 3 x TransformerBlock(
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (drop): Dropout(p=0.1, inplace=False)
      (attention): MultiheadDiffAttn(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (out_proj): Linear(in_features=128, out_features=128, bias=False)
        (subln): RMSNorm(dim=16, eps=1e-05, elementwise_affine=True)
      )
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=512, out_features=128, bias=True)
        (3): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (predict_dropout): Dropout(p=0.1, inplace=False)
  (action_head): MLPBlock(
    (model): Sequential(
      (0): Linear(in_features=128, out_features=6, bias=True)
      (1): Tanh()
    )
  )
  (reward_head): MLPBlock(
    (model): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=128, out_features=1, bias=True)
    )
  )
)
Total parameters: 745367
-----------------------------------------------
| eval/                            |          |
|    12000.0_normalized_score_mean | 216.845  |
|    12000.0_normalized_score_std  | 125.686  |
|    12000.0_reward_mean           | 216.845  |
|    12000.0_reward_std            | 125.686  |
|    6000.0_normalized_score_mean  | 221.109  |
|    6000.0_normalized_score_std   | 121.67   |
|    6000.0_reward_mean            | 221.109  |
|    6000.0_reward_std             | 121.67   |
-----------------------------------------------
